{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymystem3 as pms\n",
    "import re\n",
    "import pandas as pd\n",
    "import joblib as jl\n",
    "import gensim as gs\n",
    "import gensim.parsing.preprocessing as gspp\n",
    "import tqdm\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lemmatizer initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms = pms.Mystem(grammar_info=False)\n",
    "lem = ms.lemmatize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize(s):\n",
    "    s = gspp.strip_non_alphanum(s)\n",
    "    s = gspp.strip_numeric(s)\n",
    "    s = gspp.strip_punctuation(s)\n",
    "    s = gspp.strip_multiple_whitespaces(s)\n",
    "    s = gspp.strip_short(s, minsize=2)\n",
    "    s = lem(s)\n",
    "    s = list(map(str.strip, s))\n",
    "    s = list(filter(None, s))\n",
    "    return s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('dataset/lenta.csv.gz')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables & settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Raw and lemmatized texts columns\n",
    "texts_col = 'text'\n",
    "texts_col_lem = 'text_lem'\n",
    "words_low_freq_lim = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if texts_col_lem not in df:\n",
    "    df[texts_col_lem] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lem_results = jl.Parallel(n_jobs=jl.cpu_count(), verbose=1, batch_size=100)(jl.delayed(lemmatize)(df[texts_col].iloc[i]) for i in range(df[texts_col].size))\n",
    "df[texts_col_lem] = lem_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering empty lemmatized documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df[texts_col_lem].map(len) > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Words frequencies\n",
    "### Creating dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_lem = df[texts_col_lem].values.tolist()\n",
    "corp_dict = gs.corpora.Dictionary(texts_lem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Words frequencies calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_freqs = {}\n",
    "for w, wid in corp_dict.token2id.items():\n",
    "    words_freqs.update({w: corp_dict.cfs.get(wid)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exporting words frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('results', exist_ok=True)\n",
    "df_words_freqs = pd.DataFrame(words_freqs, index=[0]).T.reset_index().rename(columns={'index': 'word', 0: 'count'}).sort_values('count', ascending=False)\n",
    "df_words_freqs.to_excel('results/word_freqs.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stop words filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stop_words = pd.read_csv('dataset/stop-words.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "less_freq_words = [corp_dict.token2id[w] for w, count in words_freqs.items() if count < words_low_freq_lim]\n",
    "stop_words = [corp_dict.token2id[w] for w in df_stop_words['word'].values.tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corp_dict.filter_tokens(stop_words + less_freq_words)\n",
    "corp_dict.compactify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with mp.Pool() as pool:\n",
    "    corpus = pool.map(corp_dict.doc2bow, texts_lem)\n",
    "    pool.close()\n",
    "    pool.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_workers = 4\n",
    "num_topics = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = gs.models.ldamulticore.LdaMulticore(corpus, num_topics=num_topics, id2word=corp_dict, workers=num_workers, iterations=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Words vs topics matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = lda.show_topics(formatted=False)\n",
    "topics_dfs = [pd.DataFrame(t[1], columns=['words', t[0]]) for t in topics]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wt = topics_dfs[0]\n",
    "for tdf in topics_dfs[1:]:\n",
    "    df_wt = pd.merge(df_wt, tdf, how='outer', left_on='words', right_on='words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wt.fillna(0).to_excel('results/words-vs-topics-matrix.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Docs vs topics matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_topics = list(map(lda.get_document_topics, corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_docs_topics = pd.DataFrame(np.zeros((len(docs_topics), num_topics + 1)), columns=['Documents'] + np.arange(num_topics).tolist())\n",
    "df_docs_topics.iloc[:, 0] = \"\"\n",
    "df_docs_topics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc_id, doc_topic in enumerate(tqdm.notebook.tqdm(docs_topics)):\n",
    "    for topic_id, topic_prob in doc_topic:\n",
    "        df_docs_topics.loc[doc_id, topic_id] = topic_prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_docs_topics['Documents'] = df[texts_col].values\n",
    "df_docs_topics.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exporting matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_docs_topics.to_excel('results/docs-vs-topics-matrix.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
